{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copyright : fast.ai - Jeremy Howard & Sylvain Gugger - 2020 (GPLv3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cellules de code et plan du notebook adaptées du livre :\n",
    "\n",
    "[Deep Learning for Coders with fastai & PyTorch](https://github.com/fastai/fastbook) de Jeremy Howard et Sylvain Gugger.\n",
    "\n",
    "The code in the original notebooks (and thus the code in this notebook) is covered by the GPL v3 license; see the [LICENSE file](https://github.com/fastai/fastbook/blob/master/LICENSE) for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai2.vision.all import *\n",
    "\n",
    "# Configuration spécifique pour show_image() sur ce dataset : images en niveaux de gris\n",
    "matplotlib.rc('image', cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Les fondamentaux - Entrainer un classifier de chiffres manuscrits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le jeu de données MNIST : le \"Hello World\" du deep learning\n",
    "- [images](https://www.google.com/search?q=mnist+dataset&tbm=isch)\n",
    "- [historique](https://en.wikipedia.org/wiki/MNIST_database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/home/jupyter/.fastai/data/mnist_sample')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.MNIST_SAMPLE)\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment charger une image en mémoire ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#6131) [Path('/home/jupyter/.fastai/data/mnist_sample/train/3/10.png'),Path('/home/jupyter/.fastai/data/mnist_sample/train/3/10000.png'),Path('/home/jupyter/.fastai/data/mnist_sample/train/3/10011.png'),Path('/home/jupyter/.fastai/data/mnist_sample/train/3/10031.png'),Path('/home/jupyter/.fastai/data/mnist_sample/train/3/10034.png'),Path('/home/jupyter/.fastai/data/mnist_sample/train/3/10042.png'),Path('/home/jupyter/.fastai/data/mnist_sample/train/3/10052.png'),Path('/home/jupyter/.fastai/data/mnist_sample/train/3/1007.png'),Path('/home/jupyter/.fastai/data/mnist_sample/train/3/10074.png'),Path('/home/jupyter/.fastai/data/mnist_sample/train/3/10091.png')...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threes = (path/'train'/'3').ls().sorted()\n",
    "sevens = (path/'train'/'7').ls().sorted()\n",
    "threes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/home/jupyter/.fastai/data/mnist_sample/train/3/10000.png')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im3_path = threes[1]\n",
    "im3_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PIL.PngImagePlugin.PngImageFile"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im3 = Image.open(im3_path)\n",
    "type(im3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA9ElEQVR4nM3Or0sDcRjH8c/pgrfBVBjCgibThiKIyTWbWF1bORhGwxARxH/AbtW0JoIGwzXRYhJhtuFY2q1ocLgbe3sGReTuuWbwkx6+r+/zQ/pncX6q+YOldSe6nG3dn8U/rTQ70L8FCGJUewvxl7NTmezNb8xIkvKugr1HSeMP6SrWOVkoTEuSyh0Gm2n3hQyObMnXnxkempRrvgD+gokzwxFAr7U7YXHZ8x4A/Dl7rbu6D2yl3etcw/F3nZgfRVI7rXM7hMUUqzzBec427x26rkmlkzEEa4nnRqnSOH2F0UUx0ePzlbuqMXAHgN6GY9if5xP8dmtHFfwjuQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28 at 0x7FDD006AB290>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, torch.Size([28, 28]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im3_t = tensor(im3)\n",
    "type(im3_t), im3_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,  29],\n",
       "        [  0,   0,   0,  48, 166, 224],\n",
       "        [  0,  93, 244, 249, 253, 187],\n",
       "        [  0, 107, 253, 253, 230,  48],\n",
       "        [  0,   3,  20,  20,  15,   0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im3_t[4:10,4:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fdd00b48610>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEQAAABECAYAAAA4E5OyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAADjElEQVR4nO2aPyh9YRjHP/f4k38L5X+ysohsUpTBhEVMJGUyGAwWg0kGkcFqlMFIyv+kSGIwKWUiUvKn5P/9DXrvcR+He+695957+vV8llPnvvd9n77n2/s8z3tOIBgMothYqQ7Ab6ggAhVEoIIIVBBBeoTf/+cUFHC6qQ4RqCACFUSggghUEIEKIlBBBCqIQAURRKpUPeHh4QGAyclJAI6PjwFYXl4GIBgMEgh8FY59fX0A3N7eAlBTUwNAU1MTAC0tLQmNVR0iCEQ4MYupl7m4uABgYmICgJWVFQDOz8/DxhUVFQFQX18fGvMbxcXFAFxeXsYSkhPay7jBkz1ke3sbgLa2NgBeX18BeH9/B6CzsxOAnZ0dAAoLCwFC+4ZlWXx8fISNXVpa8iK0qFGHCDxxyN3dHQBPT09h98vLywGYmpoCoKys7Nc5LMsKu0p6enrijtMN6hCBJ1nm8/MTgOfn57D75mlnZWVFnOPq6gqAxsZGwM5I2dnZAOzu7gJQW1vrJiQ3aJZxgyd7iHFCTk5OzHNUVlYCdmYyzjDVrYfO+BN1iCApvYzk5eUFgM3NTQCGhoZCzsjMzARgenoagIGBgaTGpg4RJMUhpnIdHh4GYH5+HrDrl++0t7cD0NXVlYzQfqAOESSk25WY+iQ/Px8g1LeYqxMlJSUAlJaWAjAyMgLYvY7pg+LAcYKkCCIxRdjJyUno3tjYGAD7+/t//tcIMjc3B0Bubm6sYWhh5oaUOMSJt7c3wHaPScn9/f2O4w8PDwGoq6uLdUl1iBtSUpg5kZGRAUBFRQUAvb29AKyurgKwsLAQNn5tbQ2IyyGOqEMEvnGIxKTV39JrdXV1QtZVhwh8k2Uke3t7ADQ3NwP2sYDh5uYGgIKCgliX0CzjBt/tIWdnZwAMDg4CP51h6pK8vLyErK8OEfhmDzF1RUdHB2AfIhnMEePp6Slg1y1xoHuIG1K6h1xfXwMwOzvL+Pg48PVpxHfMS+6trS3AE2f8iTpE4KlDzBPf2NgA7I9bHh8fATg4OADg6OgIsM807u/vQ3OkpaUB9qvLmZkZIHFZRaIOEXiaZbq7uwFYXFyMOpDW1lYARkdHAWhoaIh6jijRLOMGTx1iPnIxtUQkzEHy+vo6VVVVXwHFf3jsFnWIG3xTqaYAdYgbVBCBCiJQQQQqiCBSL5O0osAvqEMEKohABRGoIAIVRKCCCP4B/PMI7HrW9/wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(im3_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6131, 6265)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three_tensors = [tensor(Image.open(o)) for o in threes]\n",
    "seven_tensors = [tensor(Image.open(o)) for o in sevens]\n",
    "len(three_tensors),len(seven_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, torch.Tensor)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(three_tensors),type(three_tensors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment stocker tous les exemples dans un tableau ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6131, 28, 28]), torch.Size([6265, 28, 28]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_threes = torch.stack(three_tensors).float()/255\n",
    "stacked_sevens = torch.stack(seven_tensors).float()/255\n",
    "stacked_threes.shape, stacked_sevens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1137],\n",
       "        [0.0000, 0.0000, 0.0000, 0.1882, 0.6510, 0.8784],\n",
       "        [0.0000, 0.3647, 0.9569, 0.9765, 0.9922, 0.7333],\n",
       "        [0.0000, 0.4196, 0.9922, 0.9922, 0.9020, 0.1882],\n",
       "        [0.0000, 0.0118, 0.0784, 0.0784, 0.0588, 0.0000]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_threes[1,4:10,4:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12396, 28, 28])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_digits = torch.cat([stacked_threes, stacked_sevens])\n",
    "stacked_digits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12396, 784])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = stacked_digits.view(-1, 28*28)\n",
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12396])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_labels = tensor([1]*len(threes) + [0]*len(sevens))\n",
    "stacked_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12396, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = stacked_labels.unsqueeze(1)\n",
    "train_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment effectuer des calculs sur un ensemble d'exemples ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Element-wise operations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean3 = stacked_threes.mean(0)\n",
    "mean3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEQAAABECAYAAAA4E5OyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAE1klEQVR4nO2byU8jPRTEf2En7AgQO4gDi9hO8P9fOIE4AGIR+xoU1kAgQAKZA6o4eUMU6O7R983IdbE66XYHv3K98rOJ5fN5PByq/usf8H+DHxADPyAGfkAM/IAY1FT4/l9OQbGvPvQMMfADYuAHxMAPiIEfEINKWSYSaL1kW/t9MWKx2JfX5T6PCp4hBpEwxEb+/f0dgFwuB0A2mwXg6emppH1+fgbg9fWVj48PAGprawGIx+MANDc3A9DU1ARAfX19yX3V1dVAeQb9FJ4hBqEYIkZYJmQyGQBub28BuLi4AGBnZweAvb09AM7PzwFIJpOFPsSEvr4+AMbHxwGYnZ0FYHR0FICuri7AMUiMqar6jHFQpniGGARiSDmtkDZcXV0BsL+/D8Da2hoAu7u7ABwcHACOOalUipeXl5J3tLW1AXB6elrS58LCAgBTU1MA9Pf3A44pYkhQeIYYhGKIMoMYoigXZw+AmprP13R2dgJuvo+NjQGf2qNnbm5uSvp4e3sD4O7uDnC6I41Rn8pK+m1eQyJCJFlG0VDkW1tbARgaGgKgo6MDcFEX5CFyuVwhIx0dHQFwcnICOF3SO8RGsbOc+w0KzxCDUAyRoivSmse6lvIrGymqgqKayWRIJBIAXF9fl/Ste6RD8il6V11dXcn93qlGjEAMURQUFUVP19ISO8/FFGWfx8dH4NNjbGxsALC1tQU4DWloaAAc2wYGBgCXXRobGwHHyrDwDDGIREMsY8QMtVrjKMtcXl4CsLm5CcDq6irr6+uAc7fqc35+HoDe3l7AOVNlsqjWMIW/KdTT/yBCaUglVyjNSKVSgIv+0tISACsrKwAsLy8XHKhYJScqBrS0tABOU6JmhuAZYhBKQyxTBF0rm2ilKp3Q6lcMSSQSBWbIX6gyJv2RPxHburu7S+6zlbOgiLTIbBd9tjygHytBnJ6eBmBkZKTQh50KelZlABWZ2tvbATeFoiol+iljEMnizk4Zu9iTiVIZUNcyZvl8vsAmlR+TySRAwdI/PDwAcHh4CMDw8DDgmGItfFCj5hliEKpAZDWjXDnAFnGkGcXPSyskmipEizlKy/peDBJTrFELWijyDDH4EUMsI2xrmaPoKDVqnlsUM0T3SDO03NcC0pYrldpticFrSEQIpCG2uKxWURLEEEVLGcBuFcRisd88ixiirKN32ixiWesXdxEjlIbYTWw7nxUt6YLdqC4uHIsRcqTb29uA8yF6l5yptEV9e6f6hxDKh2i+q/CjzSQ5UGUCRdEu3IR0Os3x8THgmCEfoj61ua1FXU9PD+BKi9apBoVniMGPGGLnp90qSKfTgCsEyV1KY3SfXcmmUqlCiUDPaAtzcHAQcI50cnIScAUkOVT5FJ9lIkYgDZGiKyrSBm0JCPf394DTA2UQfS6NyWazBdboGMTMzAwAc3NzACwuLgIwMTEBOA0pVw8JCs8Qg0AaomhK2VUA1haBXcvY+8/OzgDnQuPxeEEjdERCtZNymmFLh2Gzi+AZYhCrcIzgyy8rHcOUY1V2kQtVK99SfBRTkbetdMkew4xg+8H/e8h3EIghZW8uc4S70tFu+N3jVGojgGfIdxApQ/4yeIZ8B35ADPyAGFRyqtH+d85fAM8QAz8gBn5ADPyAGPgBMfADYvALMumtb+Vr5kIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(mean3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Broadcasting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6131, 28, 28])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_3_abs = (stacked_threes - mean3).abs()\n",
    "diff_3_abs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fdd005d5190>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(diff_3_abs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6131])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_3_abs = diff_3_abs.mean((-1,-2))\n",
    "dist_3_abs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Règles du broadcasting** dans numpy et PyTorch :\n",
    "1. Si les tableaux n'ont pas le même rang, préfixer la forme du tableau de rang inférieur avec des 1 jusqu'à ce que les deux formes aient la même longueur.\n",
    "2. Les deux tableaux sont compatibles dans une dimension :\n",
    "   - s'ils ont la même taille dans la dimension\n",
    "   - ou si l'un des tableaux a la taille 1 dans cette dimension.\n",
    "3. Chaque tableau se comporte comme s'il avait une forme égale au maximum des formes des deux tableaux d'entrée. Dans toute dimension où un tableau a une taille de 1 et l'autre tableau a une taille supérieure à 1, le premier tableau se comporte comme s'il était copié dans cette dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quel modèle pour reconnaitre des images de chiffres ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel:    \n",
    "    \n",
    "    @staticmethod\n",
    "    def init_params(size): \n",
    "        return torch.randn(size).requires_grad_()\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.params = (LinearModel.init_params(28*28), LinearModel.init_params(1))\n",
    "            \n",
    "    def __call__(self, inputs):\n",
    "        weights,bias = self.params\n",
    "        return inputs@weights + bias\n",
    "    \n",
    "    def predict(self, inputs):\n",
    "        activations = self(inputs)\n",
    "        return activations > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([13.1980,  2.2042,  5.8687,  8.7576, 12.6565, 13.8533, 22.1850, -1.1307],\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations = model(train_x)\n",
    "activations[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True,  True,  True,  True,  True,  True, False])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(train_x)\n",
    "predictions[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment mesurer l'erreur de prédiction ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Métrique de performance (metrics)** - pour le data scientist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True,  True,  True,  True,  True,  True, False])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrects = (predictions == stacked_labels)\n",
    "corrects[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 0.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrects[:8].float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8750)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrects[:8].float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, targets):\n",
    "    corrects = (predictions == targets)\n",
    "    return corrects.float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7784)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(predictions, stacked_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fonction de coût (loss function)** - pour le processus d'ajustement des paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 0.9006, 0.9972, 0.9998, 1.0000, 1.0000, 1.0000, 0.2440],\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_between_0_and_1 = torch.sigmoid(activations)\n",
    "scores_between_0_and_1[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.9073e-06, 9.9371e-02, 2.8185e-03, 1.5724e-04, 3.2187e-06, 9.5367e-07,\n",
       "        0.0000e+00, 7.5596e-01], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances = torch.where(stacked_labels==1, 1 - scores_between_0_and_1 , \n",
    "                                           scores_between_0_and_1 - 0 )\n",
    "distances[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_loss(activations, targets):\n",
    "    activations_01 = activations.sigmoid()\n",
    "    distances = torch.where(targets==1, \n",
    "                            1 - activations_01, \n",
    "                            activations_01)\n",
    "    return distances.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2318, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_loss(activations, stacked_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment anticiper la variation de l'erreur ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Approche expérimentale (coût de calcul +++)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(-4.1723e-06, grad_fn=<DivBackward0>),\n",
       " tensor(-1.8477e-05, grad_fn=<DivBackward0>),\n",
       " tensor(-0.0002, grad_fn=<DivBackward0>)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearModel()\n",
    "\n",
    "initial_weights = model.params[0]\n",
    "initial_bias = model.params[1]\n",
    "loss = mnist_loss(model(train_x), stacked_labels)\n",
    "\n",
    "weights0 = initial_weights.clone(); weights0[142] += 0.1\n",
    "model.params = (weights0, initial_bias)\n",
    "loss0 = mnist_loss(model(train_x), stacked_labels)\n",
    "loss_var_when_p0_changes = (loss0 - loss)/0.1\n",
    "\n",
    "weights1 = initial_weights.clone(); weights1[143] += 0.1\n",
    "model.params = (weights1, initial_bias)\n",
    "loss1 = mnist_loss(model(train_x), stacked_labels)\n",
    "loss_var_when_p1_changes = (loss1 - loss)/0.1\n",
    "\n",
    "weights2 = initial_weights.clone(); weights2[144] += 0.1\n",
    "model.params = (weights2, initial_bias)\n",
    "loss2 = mnist_loss(model(train_x), stacked_labels)\n",
    "loss_var_when_p2_changes = (loss2 - loss)/0.1\n",
    "\n",
    "# ... à faire pour chaque paramètre, soit 785 fois ...\n",
    "\n",
    "model.params = (initial_weights, initial_bias)\n",
    "\n",
    "[loss_var_when_p0_changes, loss_var_when_p1_changes, loss_var_when_p2_changes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calcul automatique du gradient par PyTorch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([784])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = mnist_loss(model(train_x), stacked_labels)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "gradient = model.params[0].grad\n",
    "gradient.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.8312e-06, -1.7906e-05, -2.2456e-04])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient[[142,143,144]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La mesure de l'erreur de prédiction par rapport aux résultats attendus est le signal qui permet de calculer un gradient puis de faire un pas dans la bonne direction pour améliorer les paramètres.\n",
    "\n",
    "Si on mesure cette erreur seulement sur deux ou trois exemples d'entrainement, on risque de faire un pas d'ajustement qui diminue l'erreur sur ces deux ou trois exemples particuliers, mais qui augmente l'erreur globalement sur tous les autres exemples.\n",
    "\n",
    "Si on mesure cette erreur sur l'ensemble des exemples d'entrainement, on ne peut faire qu'un seul pas d'ajustement à chaque passage sur la totalité des données d'entrainement : l'entrainement va converger très lentement et durer un temps infini, on gâche beaucoup de capacités de calcul.\n",
    "\n",
    "En pratique, on trouve un compromis en calculant l'erreur sur les données paquet par paquet (**mini-batchs** de données) :\n",
    "- on choisit une **taille de batch** (le nombre d'exemples examinés à chaque itération) suffisamment grande pour que la mesure de l'erreur donne une bonne approximation du gradient sur l'ensemble du jeu d'entrainement\n",
    "- on choisit une taille de batch suffisamment petite pour pouvoir appliquer un pas d'amélioration des paramètres du modèle aussi souvent que possible, réduire le temps de calul à chaque itération, pour accélérer la convergence du processus\n",
    "\n",
    "De plus, les cartes graphiques (GPUs) sont optimisés pour réaliser les mêmes opérations simultanément sur un batch de données similaires. \n",
    "\n",
    "Concrètement, on sélectionne en général la taille des mini-batchs en **fonction de la capacité mémoire du GPU**, pour tirer le maximum des capacités de calcul du matériel. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment parcourir le jeu de données par mini-batch ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset : couples (input,label)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12396"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = list(zip(train_x,train_y))\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tuple, torch.Size([784]), tensor([1]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_item = train_dataset[0]\n",
    "type(first_item), first_item[0].shape, first_item[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DataLoader : mini-batchs (inputs,labels)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La **classe fastai2 Dataloader** a pour mission de créer des batches de données à partir d'un flux d'exemples fournis par une Datasource.\n",
    "\n",
    "Pour apporter plus de variété à chaque époque et éviter une source potentielle de sur-spécialisation si on présentait de manière répétée toujours les mêmes batches dans la boucle d'apprentissage, on re-mélange les exemples de données de manière aléatoire en début de chaque époque avant de constituer des batchs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastai2.data.load.DataLoader"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dl = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "type(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tuple, torch.Size([256, 784]), torch.Size([256, 1]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_batch = train_dl.one_batch()\n",
    "type(first_batch), first_batch[0].shape, first_batch[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On réalise la même mise en forme sur le **jeu de données de validation** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemins de fichiers\n",
    "threes_valid = (path/'valid'/'3').ls().sorted()\n",
    "sevens_valid = (path/'valid'/'7').ls().sorted()\n",
    "# Liste de tensors\n",
    "three_tensors_valid = [tensor(Image.open(o)) for o in threes_valid]\n",
    "seven_tensors_valid = [tensor(Image.open(o)) for o in sevens_valid]\n",
    "# Tableaux uniques - images\n",
    "stacked_threes_valid = torch.stack(three_tensors_valid).float()/255\n",
    "stacked_sevens_valid = torch.stack(seven_tensors_valid).float()/255\n",
    "valid_x = torch.cat([stacked_threes_valid, stacked_sevens_valid]).view(-1, 28*28)\n",
    "# Tableaux uniques - labels\n",
    "stacked_labels_valid = tensor([1]*len(threes_valid) + [0]*len(sevens_valid))\n",
    "valid_y = stacked_labels_valid.unsqueeze(1)\n",
    "# Dataset\n",
    "valid_dataset = list(zip(valid_x,valid_y))\n",
    "# Dataloader\n",
    "valid_dl = DataLoader(valid_dataset, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment réaliser une boucle d’apprentissage ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Création de deux DataLoaders pour les jeux d'entrainement et de validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La **classe fastai2 Dataloaders** permet de regrouper les Dataloader des jeu de données d'entrainement et de validation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 8)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls = DataLoaders(train_dl,valid_dl)\n",
    "len(dls.train),len(dls.valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Choix d'un modèle de prédiction avec des paramètres ajustables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel:    \n",
    "    \n",
    "    @staticmethod\n",
    "    def init_params(size): \n",
    "        return torch.randn(size).requires_grad_()\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.params = (LinearModel.init_params(28*28), LinearModel.init_params(1))\n",
    "            \n",
    "    def __call__(self, inputs):\n",
    "        weights,bias = self.params\n",
    "        return inputs@weights + bias\n",
    "    \n",
    "    def predict(self, inputs):\n",
    "        activations = self(inputs)\n",
    "        return activations.sigmoid() > 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Définition de fonctions de mesure de l'erreur de prédiction : loss function et métrique(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, targets):\n",
    "    corrects = (predictions == targets)\n",
    "    return corrects.float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_loss(activations, targets):\n",
    "    activations_01 = activations.sigmoid()\n",
    "    distances = torch.where(targets==1, \n",
    "                            1 - activations_01, \n",
    "                            activations_01)\n",
    "    return distances.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Anticipation de l'évolution de l'erreur pour un petit ajustement des paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(xb, yb, model, loss_func):\n",
    "    activations = model(xb)\n",
    "    loss = loss_func(activations, yb)\n",
    "    loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Ajustement des paramètres sur un mini-batch de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGDOptimizer:\n",
    "    \n",
    "    def __init__(self, model, lr):\n",
    "        self.params = list(model.params)\n",
    "        self.lr = lr\n",
    "    \n",
    "    def adjust_params(self):\n",
    "        for param_tensor in self.params:\n",
    "            param_tensor.data -= self.lr * param_tensor.grad\n",
    "            \n",
    "    def zero_grad(self):\n",
    "        for param_tensor in self.params:\n",
    "            param_tensor.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Entrainement sur une époque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(train_dl, model, loss_func, optim):\n",
    "    for xb,yb in train_dl:\n",
    "        compute_gradient(xb, yb, model, loss_func)\n",
    "        optim.adjust_params()\n",
    "        optim.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Calcul des métriques de performances sur le jeu de données de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_epoch(valid_dl, model, metric):\n",
    "    perfs = [batch_perf(xb, yb, model, metric) for xb,yb in valid_dl]\n",
    "    return round(torch.stack(perfs).mean().item(), 4)\n",
    "\n",
    "def batch_perf(xb, yb, model, metric):\n",
    "    predictions = model.predict(xb)\n",
    "    return metric(predictions, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Entrainement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(dls, model, loss_func, metric, optim, epochs):\n",
    "    for i in range(epochs):\n",
    "        train_epoch(dls.train, model, loss_func, optim)\n",
    "        print(validate_epoch(dls.valid, model, metric), end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Exécution de l'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearModel()\n",
    "sgd = SGDOptimizer(model, lr=1.)\n",
    "\n",
    "train_model(dls, model, loss_func=mnist_loss, metric=accuracy, optim=sgd, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utiliser les classes de PyTorch et fastai2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le module PyTorch **nn.Linear** est l'équivalent de notre classe LinearModel :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(28*28,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'optimiseur PyTorch **SGD** est l'équivalent de notre classe SGDOptimizer :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = SGD(model.parameters(), lr=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fastai2 définit une métrique **accuracy** (que nous avions redéfinie) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai2.metrics import accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La classe fastai2 **Learner** permet de regrouper :\n",
    "- les jeux de données d'entrainement et de validation\n",
    "- le modèle et ses paramètres\n",
    "- l'optimiseur : opt_func\n",
    "- la fonction de mesure de l'erreur pour calculer le gradient : loss_func\n",
    "- les indicateurs de performance qui intéressent le data scientist : metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, nn.Linear(28*28,1), opt_func=SGD,\n",
    "                loss_func=mnist_loss, metrics=accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sa **méthode fit(epochs, learning_rate)** est l'équivalent de notre fonction train_model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, lr=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On retrouve une performance de classification finale de l'ordre de 97%.\n",
    "\n",
    "Pour aller plus loin, on peut remplacer notre modèle linéaire par un modèle un tout petit peu plus compliqué : des combinaisons de segments au lieu de simples droites. \n",
    "\n",
    "On définit ainsi un réseau de neurones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création d'un réseau de neurones à un niveau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un niveau de **réseau de neurone** (feed-forward ou fully-connected) se traduit par l'enchainement des 3 modules suivants :\n",
    "- production de 30 combinaisons linéaires différentes des 28*28 paramètres d'entrée (23 550 paramètres à ajuster)\n",
    "- ajout d'une non linéarité (création de \"segments de droite\" à combiner)\n",
    "- combinaisation linéaire des 30 valeurs intermédiaires pour produire une prédiction (31 paramètres à ajuster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_net = nn.Sequential(\n",
    "    nn.Linear(28*28,30),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30,1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essayons d'entrainer ce nouveau modèle de la même manière :\n",
    "- le précédent modèle avait 785 paramètres à ajuster\n",
    "- le nouveau modèle a 23 581 paramètres à ajuster (30x plus de capacité de calcul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, simple_net, opt_func=SGD,\n",
    "               loss_func=mnist_loss, metrics=accuracy,\n",
    "               cbs=ShowGraphCallback())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(40, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nouvelle tentative avec un réseau de neurones à 18 niveaux : **retour aux 3 lignes de code de la précédente session**\n",
    "- le précédent modèle avait 23 581 paramètres à ajuster\n",
    "- le nouveau modèle a 17986 paramètres à ajuster (2x moins de capacité de calcul)\n",
    "- mais le nouveau modèle a une architecture beaucoup mieux adaptée au problème\n",
    "- l'étude de cette architecture sera l'objet d'une prochaine session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.102150</td>\n",
       "      <td>100.410500</td>\n",
       "      <td>0.996075</td>\n",
       "      <td>00:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls = ImageDataLoaders.from_folder(path,bs=32)\n",
    "learn = cnn_learner(dls, resnet18, pretrained=False,\n",
    "                    loss_func=F.cross_entropy, metrics=accuracy)\n",
    "learn.fit_one_cycle(1, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On atteint un taux de succès de classification de **99.7%** en 20 secondes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17986"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nombre de paramètres du modèle\n",
    "np.sum([len(layerparams.data) for layerparams in learn.model.parameters()])"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
