{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copyright : fast.ai - Jeremy Howard & Sylvain Gugger - 2020 (GPLv3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cellules de code et plan du notebook adaptées du livre :\n",
    "\n",
    "[Deep Learning for Coders with fastai & PyTorch](https://github.com/fastai/fastbook) de Jeremy Howard et Sylvain Gugger.\n",
    "\n",
    "The code in the original notebooks (and thus the code in this notebook) is covered by the GPL v3 license; see the [LICENSE file](https://github.com/fastai/fastbook/blob/master/LICENSE) for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai2.vision.all import *\n",
    "\n",
    "# Configuration spécifique pour show_image() sur ce dataset : images en niveaux de gris\n",
    "matplotlib.rc('image', cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Les fondamentaux - Entrainer un classifier de chiffres manuscrits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le jeu de données MNIST : le \"Hello World\" du deep learning\n",
    "- [images](https://www.google.com/search?q=mnist+dataset&tbm=isch)\n",
    "- [historique](https://en.wikipedia.org/wiki/MNIST_database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/storage/data/mnist_sample')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "untar_data(URLs.MNIST_SAMPLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment charger une image en mémoire ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/storage/data/mnist_sample')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path('/storage/data/mnist_sample')\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#6131) [Path('/storage/data/mnist_sample/train/3/10.png'),Path('/storage/data/mnist_sample/train/3/10000.png'),Path('/storage/data/mnist_sample/train/3/10011.png'),Path('/storage/data/mnist_sample/train/3/10031.png'),Path('/storage/data/mnist_sample/train/3/10034.png'),Path('/storage/data/mnist_sample/train/3/10042.png'),Path('/storage/data/mnist_sample/train/3/10052.png'),Path('/storage/data/mnist_sample/train/3/1007.png'),Path('/storage/data/mnist_sample/train/3/10074.png'),Path('/storage/data/mnist_sample/train/3/10091.png')...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threes = (path/'train'/'3').ls().sorted()\n",
    "sevens = (path/'train'/'7').ls().sorted()\n",
    "threes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/storage/data/mnist_sample/train/3/10000.png')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im3_path = threes[1]\n",
    "im3_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PIL.PngImagePlugin.PngImageFile"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im3 = Image.open(im3_path)\n",
    "type(im3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA9ElEQVR4nM3Or0sDcRjH8c/pgrfBVBjCgibThiKIyTWbWF1bORhGwxARxH/AbtW0JoIGwzXRYhJhtuFY2q1ocLgbe3sGReTuuWbwkx6+r+/zQ/pncX6q+YOldSe6nG3dn8U/rTQ70L8FCGJUewvxl7NTmezNb8xIkvKugr1HSeMP6SrWOVkoTEuSyh0Gm2n3hQyObMnXnxkempRrvgD+gokzwxFAr7U7YXHZ8x4A/Dl7rbu6D2yl3etcw/F3nZgfRVI7rXM7hMUUqzzBec427x26rkmlkzEEa4nnRqnSOH2F0UUx0ePzlbuqMXAHgN6GY9if5xP8dmtHFfwjuQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28 at 0x7F4B5B871050>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, torch.Size([28, 28]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im3_t = tensor(im3)\n",
    "type(im3_t), im3_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,  29],\n",
       "        [  0,   0,   0,  48, 166, 224],\n",
       "        [  0,  93, 244, 249, 253, 187],\n",
       "        [  0, 107, 253, 253, 230,  48],\n",
       "        [  0,   3,  20,  20,  15,   0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im3_t[4:10,4:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f4b5b7f0990>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(im3_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6131, 6265)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three_tensors = [tensor(Image.open(o)) for o in threes]\n",
    "seven_tensors = [tensor(Image.open(o)) for o in sevens]\n",
    "len(three_tensors),len(seven_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, torch.Tensor)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(three_tensors),type(three_tensors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment stocker tous les exemples dans un tableau ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6131, 28, 28]), torch.Size([6265, 28, 28]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_threes = torch.stack(three_tensors).float()/255\n",
    "stacked_sevens = torch.stack(seven_tensors).float()/255\n",
    "stacked_threes.shape, stacked_sevens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1137],\n",
       "        [0.0000, 0.0000, 0.0000, 0.1882, 0.6510, 0.8784],\n",
       "        [0.0000, 0.3647, 0.9569, 0.9765, 0.9922, 0.7333],\n",
       "        [0.0000, 0.4196, 0.9922, 0.9922, 0.9020, 0.1882],\n",
       "        [0.0000, 0.0118, 0.0784, 0.0784, 0.0588, 0.0000]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_threes[1,4:10,4:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12396, 28, 28])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_digits = torch.cat([stacked_threes, stacked_sevens])\n",
    "stacked_digits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12396, 784])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = stacked_digits.view(-1, 28*28)\n",
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12396])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_labels = tensor([1]*len(threes) + [0]*len(sevens))\n",
    "stacked_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12396, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = stacked_labels.unsqueeze(1)\n",
    "train_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment effectuer des calculs sur un ensemble d'exemples ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Element-wise operations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean3 = stacked_threes.mean(0)\n",
    "mean3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(mean3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Broadcasting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6131, 28, 28])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_3_abs = (stacked_threes - mean3).abs()\n",
    "diff_3_abs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f2d23189f90>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(diff_3_abs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6131])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_3_abs = diff_3_abs.mean((-1,-2))\n",
    "dist_3_abs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Règles du broadcasting** dans numpy et PyTorch :\n",
    "1. Si les tableaux n'ont pas le même rang, préfixer la forme du tableau de rang inférieur avec des 1 jusqu'à ce que les deux formes aient la même longueur.\n",
    "2. Les deux tableaux sont compatibles dans une dimension :\n",
    "   - s'ils ont la même taille dans la dimension\n",
    "   - ou si l'un des tableaux a la taille 1 dans cette dimension.\n",
    "3. Chaque tableau se comporte comme s'il avait une forme égale au maximum des formes des deux tableaux d'entrée. Dans toute dimension où un tableau a une taille de 1 et l'autre tableau a une taille supérieure à 1, le premier tableau se comporte comme s'il était copié dans cette dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quel modèle pour reconnaitre des images de chiffres ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel:    \n",
    "    \n",
    "    @staticmethod\n",
    "    def init_params(size): \n",
    "        return torch.randn(size).requires_grad_()\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.params = (LinearModel.init_params(28*28), LinearModel.init_params(1))\n",
    "            \n",
    "    def __call__(self, inputs):\n",
    "        weights,bias = self.params\n",
    "        return inputs@weights + bias\n",
    "    \n",
    "    def predict(self, inputs):\n",
    "        activations = self(inputs)\n",
    "        return activations > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ -3.7598,  -2.6427, -12.3079,  -5.3162,  -7.2536,   4.6322,  -5.2162,\n",
       "        -13.0789], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations = model(train_x)\n",
    "activations[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False, False,  True, False, False])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(train_x)\n",
    "predictions[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment mesurer l'erreur de prédiction ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Métrique de performance (metrics)** - pour le data scientist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False, False,  True, False, False])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrects = (predictions == stacked_labels)\n",
    "corrects[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrects[:8].float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1250)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrects[:8].float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, targets):\n",
    "    corrects = (predictions == targets)\n",
    "    return corrects.float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5712)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(predictions, stacked_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fonction de coût (loss function)** - pour le processus d'ajustement des paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 0.4904, 1.0000, 0.0052, 1.0000, 0.9972, 1.0000],\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_between_0_and_1 = torch.sigmoid(activations)\n",
    "scores_between_0_and_1[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.9220e-05, 2.3723e-05, 5.0964e-01, 5.2452e-06, 9.9485e-01, 3.0279e-05,\n",
       "        2.7891e-03, 4.7684e-07], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances = torch.where(stacked_labels==1, 1 - scores_between_0_and_1 , \n",
    "                                           scores_between_0_and_1 - 0 )\n",
    "distances[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_loss(activations, targets):\n",
    "    activations_01 = activations.sigmoid()\n",
    "    distances = torch.where(targets==1, \n",
    "                            1 - activations_01, \n",
    "                            activations_01)\n",
    "    return distances.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5215, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_loss(activations, stacked_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment anticiper la variation de l'erreur ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Approche expérimentale (coût de calcul +++)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0., grad_fn=<DivBackward0>),\n",
       " tensor(7.1526e-06, grad_fn=<DivBackward0>),\n",
       " tensor(-8.8513e-05, grad_fn=<DivBackward0>)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearModel()\n",
    "\n",
    "initial_weights = model.params[0]\n",
    "initial_bias = model.params[1]\n",
    "loss = mnist_loss(model(train_x), stacked_labels)\n",
    "\n",
    "weights0 = initial_weights.clone(); weights0[142] += 0.1\n",
    "model.params = (weights0, initial_bias)\n",
    "loss0 = mnist_loss(model(train_x), stacked_labels)\n",
    "loss_var_when_p0_changes = (loss0 - loss)/0.1\n",
    "\n",
    "weights1 = initial_weights.clone(); weights1[143] += 0.1\n",
    "model.params = (weights1, initial_bias)\n",
    "loss1 = mnist_loss(model(train_x), stacked_labels)\n",
    "loss_var_when_p1_changes = (loss1 - loss)/0.1\n",
    "\n",
    "weights2 = initial_weights.clone(); weights2[144] += 0.1\n",
    "model.params = (weights2, initial_bias)\n",
    "loss2 = mnist_loss(model(train_x), stacked_labels)\n",
    "loss_var_when_p2_changes = (loss2 - loss)/0.1\n",
    "\n",
    "# ... à faire pour chaque paramètre, soit 785 fois ...\n",
    "\n",
    "model.params = (initial_weights, initial_bias)\n",
    "\n",
    "[loss_var_when_p0_changes, loss_var_when_p1_changes, loss_var_when_p2_changes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calcul automatique du gradient par PyTorch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([784])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = mnist_loss(model(train_x), stacked_labels)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "gradient = model.params[0].grad\n",
    "gradient.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-4.0840e-08,  6.9461e-06, -8.9936e-05])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient[[142,143,144]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La mesure de l'erreur de prédiction par rapport aux résultats attendus est le signal qui permet de calculer un gradient puis de faire un pas dans la bonne direction pour améliorer les paramètres.\n",
    "\n",
    "Si on mesure cette erreur seulement sur deux ou trois exemples d'entrainement, on risque de faire un pas d'ajustement qui diminue l'erreur sur ces deux ou trois exemples particuliers, mais qui augmente l'erreur globalement sur tous les autres exemples.\n",
    "\n",
    "Si on mesure cette erreur sur l'ensemble des exemples d'entrainement, on ne peut faire qu'un seul pas d'ajustement à chaque passage sur la totalité des données d'entrainement : l'entrainement va converger très lentement et durer un temps infini, on gâche beaucoup de capacités de calcul.\n",
    "\n",
    "En pratique, on trouve un compromis en calculant l'erreur sur les données paquet par paquet (**mini-batchs** de données) :\n",
    "- on choisit une **taille de batch** (le nombre d'exemples examinés à chaque itération) suffisamment grande pour que la mesure de l'erreur donne une bonne approximation du gradient sur l'ensemble du jeu d'entrainement\n",
    "- on choisit une taille de batch suffisamment petite pour pouvoir appliquer un pas d'amélioration des paramètres du modèle aussi souvent que possible, réduire le temps de calul à chaque itération, pour accélérer la convergence du processus\n",
    "\n",
    "De plus, les cartes graphiques (GPUs) sont optimisés pour réaliser les mêmes opérations simultanément sur un batch de données similaires. \n",
    "\n",
    "Concrètement, on sélectionne en général la taille des mini-batchs en **fonction de la capacité mémoire du GPU**, pour tirer le maximum des capacités de calcul du matériel. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment parcourir le jeu de données par mini-batch ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset : couples (input,label)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12396"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = list(zip(train_x,train_y))\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tuple, torch.Size([784]), tensor([1]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_item = train_dataset[0]\n",
    "type(first_item), first_item[0].shape, first_item[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DataLoader : mini-batchs (inputs,labels)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La **classe fastai2 Dataloader** a pour mission de créer des batches de données à partir d'un flux d'exemples fournis par une Datasource.\n",
    "\n",
    "Pour apporter plus de variété à chaque époque et éviter une source potentielle de sur-spécialisation si on présentait de manière répétée toujours les mêmes batches dans la boucle d'apprentissage, on re-mélange les exemples de données de manière aléatoire en début de chaque époque avant de constituer des batchs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastai2.data.load.DataLoader"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dl = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "type(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tuple, torch.Size([256, 784]), torch.Size([256, 1]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_batch = train_dl.one_batch()\n",
    "type(first_batch), first_batch[0].shape, first_batch[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On réalise la même mise en forme sur le **jeu de données de validation** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemins de fichiers\n",
    "threes_valid = (path/'valid'/'3').ls().sorted()\n",
    "sevens_valid = (path/'valid'/'7').ls().sorted()\n",
    "# Liste de tensors\n",
    "three_tensors_valid = [tensor(Image.open(o)) for o in threes_valid]\n",
    "seven_tensors_valid = [tensor(Image.open(o)) for o in sevens_valid]\n",
    "# Tableaux uniques - images\n",
    "stacked_threes_valid = torch.stack(three_tensors_valid).float()/255\n",
    "stacked_sevens_valid = torch.stack(seven_tensors_valid).float()/255\n",
    "valid_x = torch.cat([stacked_threes_valid, stacked_sevens_valid]).view(-1, 28*28)\n",
    "# Tableaux uniques - labels\n",
    "stacked_labels_valid = tensor([1]*len(three_tensors_valid) + [0]*len(seven_tensors_valid))\n",
    "valid_y = stacked_labels_valid.unsqueeze(1)\n",
    "# Dataset\n",
    "valid_dataset = list(zip(valid_x,valid_y))\n",
    "# Dataloader\n",
    "valid_dl = DataLoader(valid_dataset, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment réaliser une boucle d’apprentissage ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Création de deux DataLoaders pour les jeux d'entrainement et de validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La **classe fastai2 Dataloaders** permet de regrouper les Dataloader des jeu de données d'entrainement et de validation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 8)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls = DataLoaders(train_dl,valid_dl)\n",
    "len(dls.train),len(dls.valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Choix d'un modèle de prédiction avec des paramètres ajustables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel:    \n",
    "    \n",
    "    @staticmethod\n",
    "    def init_params(size): \n",
    "        return torch.randn(size).requires_grad_()\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.params = (LinearModel.init_params(28*28), LinearModel.init_params(1))\n",
    "            \n",
    "    def __call__(self, inputs):\n",
    "        weights,bias = self.params\n",
    "        return inputs@weights + bias\n",
    "    \n",
    "    def predict(self, inputs):\n",
    "        activations = self(inputs)\n",
    "        return activations.sigmoid() > 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Définition de fonctions de mesure de l'erreur de prédiction : loss function et métrique(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, targets):\n",
    "    corrects = (predictions == targets)\n",
    "    return corrects.float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_loss(activations, targets):\n",
    "    activations_01 = activations.sigmoid()\n",
    "    distances = torch.where(targets==1, \n",
    "                            1 - activations_01, \n",
    "                            activations_01)\n",
    "    return distances.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Anticipation de l'évolution de l'erreur pour un petit ajustement des paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(xb, yb, model, loss_func):\n",
    "    activations = model(xb)\n",
    "    loss = loss_func(activations, yb)\n",
    "    loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Ajustement des paramètres sur un mini-batch de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGDOptimizer:\n",
    "    \n",
    "    def __init__(self, model, lr):\n",
    "        self.params = list(model.params)\n",
    "        self.lr = lr\n",
    "    \n",
    "    def adjust_params(self):\n",
    "        for param_tensor in self.params:\n",
    "            param_tensor.data -= self.lr * param_tensor.grad\n",
    "            \n",
    "    def zero_grad(self):\n",
    "        for param_tensor in self.params:\n",
    "            param_tensor.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Entrainement sur une époque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(train_dl, model, loss_func, optim):\n",
    "    for xb,yb in train_dl:\n",
    "        compute_gradient(xb, yb, model, loss_func)\n",
    "        optim.adjust_params()\n",
    "        optim.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Calcul des métriques de performances sur le jeu de données de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_epoch(valid_dl, model, metric):\n",
    "    perfs = [batch_perf(xb, yb, model, metric) for xb,yb in valid_dl]\n",
    "    return round(torch.stack(perfs).mean().item(), 4)\n",
    "\n",
    "def batch_perf(xb, yb, model, metric):\n",
    "    predictions = model.predict(xb)\n",
    "    return metric(predictions, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Entrainement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(dls, model, loss_func, metric, optim, epochs):\n",
    "    for i in range(epochs):\n",
    "        train_epoch(dls.train, model, loss_func, optim)\n",
    "        print(validate_epoch(dls.valid, model, metric), end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Exécution de l'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5028 0.5029 0.5031 0.5032 0.504 0.5036 0.5042 0.5043 0.5036 0.5045 0.5039 0.504 0.5041 0.5038 0.5046 0.5042 0.5045 0.504 0.5042 0.5045 "
     ]
    }
   ],
   "source": [
    "model = LinearModel()\n",
    "sgd = SGDOptimizer(model, lr=1.)\n",
    "\n",
    "train_model(dls, model, loss_func=mnist_loss, metric=accuracy, optim=sgd, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utiliser les classes de PyTorch et fastai2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le module PyTorch **nn.Linear** est l'équivalent de notre classe LinearModel :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(28*28,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'optimiseur PyTorch **SGD** est l'équivalent de notre classe SGDOptimizer :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = SGD(model.parameters(), lr=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fastai2 définit une métrique **accuracy** (que nous avions redéfinie) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai2.metrics import accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La classe fastai2 **Learner** permet de regrouper :\n",
    "- les jeux de données d'entrainement et de validation\n",
    "- le modèle et ses paramètres\n",
    "- l'optimiseur : opt_func\n",
    "- la fonction de mesure de l'erreur pour calculer le gradient : loss_func\n",
    "- les indicateurs de performance qui intéressent le data scientist : metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, nn.Linear(28*28,1), opt_func=SGD,\n",
    "                loss_func=mnist_loss, metrics=accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sa **méthode fit(epochs, learning_rate)** est l'équivalent de notre fonction train_model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.057644</td>\n",
       "      <td>0.041220</td>\n",
       "      <td>0.504416</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.039630</td>\n",
       "      <td>0.034940</td>\n",
       "      <td>0.504416</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.032057</td>\n",
       "      <td>0.031637</td>\n",
       "      <td>0.504416</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.027831</td>\n",
       "      <td>0.029447</td>\n",
       "      <td>0.504416</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.025445</td>\n",
       "      <td>0.028981</td>\n",
       "      <td>0.504416</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.023805</td>\n",
       "      <td>0.027806</td>\n",
       "      <td>0.504416</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.022306</td>\n",
       "      <td>0.026337</td>\n",
       "      <td>0.504416</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.021494</td>\n",
       "      <td>0.025529</td>\n",
       "      <td>0.504416</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.020595</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.504416</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.019777</td>\n",
       "      <td>0.024309</td>\n",
       "      <td>0.504416</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(10, lr=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On retrouve une performance de classification finale de l'ordre de 97%.\n",
    "\n",
    "Pour aller plus loin, on peut remplacer notre modèle linéaire par un modèle un tout petit peu plus compliqué : des combinaisons de segments au lieu de simples droites. \n",
    "\n",
    "On définit ainsi un réseau de neurones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création d'un réseau de neurones à un niveau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un niveau de **réseau de neurone** (feed-forward ou fully-connected) se traduit par l'enchainement des 3 modules suivants :\n",
    "- production de 30 combinaisons linéaires différentes des 28*28 paramètres d'entrée (23 550 paramètres à ajuster)\n",
    "- ajout d'une non linéarité (création de \"segments de droite\" à combiner)\n",
    "- combinaisation linéaire des 30 valeurs intermédiaires pour produire une prédiction (31 paramètres à ajuster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_net = nn.Sequential(\n",
    "    nn.Linear(28*28,30),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30,1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essayons d'entrainer ce nouveau modèle de la même manière :\n",
    "- le précédent modèle avait 785 paramètres à ajuster\n",
    "- le nouveau modèle a 23 581 paramètres à ajuster (30x plus de capacité de calcul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, simple_net, opt_func=SGD,\n",
    "               loss_func=mnist_loss, metrics=accuracy,\n",
    "               cbs=ShowGraphCallback())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.226238</td>\n",
       "      <td>0.090654</td>\n",
       "      <td>0.504416</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.108325</td>\n",
       "      <td>0.054289</td>\n",
       "      <td>0.504416</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.066756</td>\n",
       "      <td>0.044734</td>\n",
       "      <td>0.504416</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.048776</td>\n",
       "      <td>0.039792</td>\n",
       "      <td>0.504416</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.039686</td>\n",
       "      <td>0.037041</td>\n",
       "      <td>0.504416</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.034393</td>\n",
       "      <td>0.034597</td>\n",
       "      <td>0.504416</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.030791</td>\n",
       "      <td>0.032940</td>\n",
       "      <td>0.504416</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.028448</td>\n",
       "      <td>0.031510</td>\n",
       "      <td>0.504416</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.026756</td>\n",
       "      <td>0.030430</td>\n",
       "      <td>0.504416</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.025547</td>\n",
       "      <td>0.029516</td>\n",
       "      <td>0.504416</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.024382</td>\n",
       "      <td>0.028816</td>\n",
       "      <td>0.504416</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.023781</td>\n",
       "      <td>0.027846</td>\n",
       "      <td>0.504416</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.022248</td>\n",
       "      <td>0.027283</td>\n",
       "      <td>0.504416</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.021934</td>\n",
       "      <td>0.026839</td>\n",
       "      <td>0.504416</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.021281</td>\n",
       "      <td>0.026389</td>\n",
       "      <td>0.504416</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.020987</td>\n",
       "      <td>0.025662</td>\n",
       "      <td>0.504416</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.020745</td>\n",
       "      <td>0.025464</td>\n",
       "      <td>0.504416</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.020215</td>\n",
       "      <td>0.025275</td>\n",
       "      <td>0.504416</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.019949</td>\n",
       "      <td>0.024751</td>\n",
       "      <td>0.504416</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.020151</td>\n",
       "      <td>0.024437</td>\n",
       "      <td>0.504416</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.019404</td>\n",
       "      <td>0.024045</td>\n",
       "      <td>0.504416</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.019016</td>\n",
       "      <td>0.023787</td>\n",
       "      <td>0.504416</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.018650</td>\n",
       "      <td>0.023391</td>\n",
       "      <td>0.504416</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.018188</td>\n",
       "      <td>0.023025</td>\n",
       "      <td>0.504416</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.017807</td>\n",
       "      <td>0.022847</td>\n",
       "      <td>0.504416</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.017435</td>\n",
       "      <td>0.022563</td>\n",
       "      <td>0.504416</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.017435</td>\n",
       "      <td>0.022334</td>\n",
       "      <td>0.504416</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.017014</td>\n",
       "      <td>0.021989</td>\n",
       "      <td>0.504416</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.017205</td>\n",
       "      <td>0.021761</td>\n",
       "      <td>0.504416</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.016802</td>\n",
       "      <td>0.021552</td>\n",
       "      <td>0.504416</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.016817</td>\n",
       "      <td>0.021546</td>\n",
       "      <td>0.504416</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.016187</td>\n",
       "      <td>0.021337</td>\n",
       "      <td>0.504416</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.016021</td>\n",
       "      <td>0.021292</td>\n",
       "      <td>0.504416</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.016299</td>\n",
       "      <td>0.020839</td>\n",
       "      <td>0.504416</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.015991</td>\n",
       "      <td>0.020781</td>\n",
       "      <td>0.504416</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.015569</td>\n",
       "      <td>0.020938</td>\n",
       "      <td>0.504416</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.015796</td>\n",
       "      <td>0.020668</td>\n",
       "      <td>0.504416</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.015381</td>\n",
       "      <td>0.020293</td>\n",
       "      <td>0.504416</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.015151</td>\n",
       "      <td>0.020452</td>\n",
       "      <td>0.504416</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.015017</td>\n",
       "      <td>0.020137</td>\n",
       "      <td>0.504416</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(40, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nouvelle tentative avec un réseau de neurones à 18 niveaux : **retour aux 3 lignes de code de la précédente session**\n",
    "- le précédent modèle avait 23 581 paramètres à ajuster\n",
    "- le nouveau modèle a 17986 paramètres à ajuster (2x moins de capacité de calcul)\n",
    "- mais le nouveau modèle a une architecture beaucoup mieux adaptée au problème\n",
    "- l'étude de cette architecture sera l'objet d'une prochaine session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.102150</td>\n",
       "      <td>100.410500</td>\n",
       "      <td>0.996075</td>\n",
       "      <td>00:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls = ImageDataLoaders.from_folder(path,bs=32)\n",
    "learn = cnn_learner(dls, resnet18, pretrained=False,\n",
    "                    loss_func=F.cross_entropy, metrics=accuracy)\n",
    "learn.fit_one_cycle(1, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On atteint un taux de succès de classification de **99.7%** en 20 secondes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17986"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nombre de paramètres du modèle\n",
    "np.sum([len(layerparams.data) for layerparams in learn.model.parameters()])"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
